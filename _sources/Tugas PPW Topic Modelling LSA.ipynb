{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2fa8319",
   "metadata": {},
   "source": [
    "# Program Topic Modelling LDA dan LSA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3b67f",
   "metadata": {},
   "source": [
    "Latent Dirichlet Allocation (LDA) adalah model probabilistik generatif dari koleksi data diskrit seperti korpus teks. Ide dasarnya adalah bahwa dokumen direpresentasikan sebagai campuran acak atas topik laten (tidak terlihat).\n",
    "\n",
    "LDA merupakan model Bayesian hirarki tiga tingkat, di mana setiap item koleksi dimodelkan sebagai campuran terbatas atas serangkaian set topik. Setiap topik dimodelkan sebagai campuran tak terbatas melalui set yang mendasari probabilitas topik. Dalam konteks pembuatan model teks, probabilitas topik memberikan representasi eksplisit dari sebuah dokumen.\n",
    "\n",
    "Algoritma LSA (Latent Semantic Analysis) adalah salah satu algoritma yang dapat digunakan untuk menganalisa hubungan antara sebuah frase/kalimat dengan sekumpulan dokumen. Contoh yang dibahas kali ini adalah mengenai penentuan urutan peringkat data berdasarkan query yang digunakan. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaab957",
   "metadata": {},
   "source": [
    "<h3>Install Library</h3>\n",
    "\n",
    "<p>Dibawah ini dicantumkan beberapa library yang dibutuhkan untuk menlakukan processing menggunakan LSA dengan jupyter notebook, anda juga bisa melakukan instalasi ini dengan menggunakan Command Prompt untuk pengguna Windows atau Terminal untuk pengguna Linux</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc2825",
   "metadata": {},
   "source": [
    "- pip install numpy\n",
    "- pip install sklearn\n",
    "- pip install pandas\n",
    "- pip install matplotlib\n",
    "- pip install seaborn\n",
    "- pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b84d5a",
   "metadata": {},
   "source": [
    "<h3>Import Library</h3>\n",
    "\n",
    "<p>Untuk library yang digunakan diantaranya ada numpy, pandas, matplotlib, seaborn, nltk, dan sklearn, library ini umum digunakan pada data processing</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724deafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "#preprocessing\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "\n",
    "# for named entity recognition (NER)\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# vectorizers for creating the document-term-matrix (DTM)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "\n",
    "#stop-words\n",
    "stop_words=set(nltk.corpus.stopwords.words('indonesian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17637b3e",
   "metadata": {},
   "source": [
    "<h3>Instalasi Library Tambahan</h3>\n",
    "<p>Di bawah ini ada library tambahan yang harus di-install untuk memproses kata-kata yang diolah</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82611360",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('corpus')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8221245",
   "metadata": {},
   "source": [
    "<h3>Import dokumen</h3>\n",
    "<p>Import dokumen yang sudah dicrawling dengan crawler, bisa menggunakan referensi dari web ini atau bisa menggunakan referensi kode dari website lain</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77d3fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'abstrak_pta_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60bce0",
   "metadata": {},
   "source": [
    "<h2>Tampilan dari 10 data yang diproses</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b485343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>abstraksi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARAKTERISTIK KONDISI OSEANOGRAFI DAN DISTRIBU...</td>\n",
       "      <td>Laut Jawa (Wilayah Pengelolaan Perikanan/ WPP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A STUDY OF METADISCOURSE MARKERS IN GRETA THUN...</td>\n",
       "      <td>Penelitian ini bertujuan untuk membahas jenis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jaringan Sosial Pengusaha Kerajinan Limbah Kay...</td>\n",
       "      <td>Ana Febrianti, 160521100004 Program Studi Sosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analisis strategi pengelolaan Pantai Syariah P...</td>\n",
       "      <td>Di Indonesia, potensi pengembangan Industri pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEMAKNAI GAYA HIDUP PENIKMAT KOPI KHAS INDONES...</td>\n",
       "      <td>Siti Maghfuro 160521100023 Program Studi Sosio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pertukaran Sosial Dalam Tradisi Sape Tok-tok</td>\n",
       "      <td>Abstrak – Farida Yulistiana Aji. \\n16052110000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Public Awareness Masyarakat Madura Tentang Kon...</td>\n",
       "      <td>Penelitian ini dengan judul “Public Awareness ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HUBUNGAN ANTARA PROKRASTINASI AKADEMIK DENGAN ...</td>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Evaluasi Tingkat Kelelahan Kerja Perawat Ruang...</td>\n",
       "      <td>Rumah sakit merupakan salah satu instansi di b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pengaruh Biochar Sekam Padi dan Pupuk Kandang ...</td>\n",
       "      <td>Biochar merupakan padatan yang kaya kandungan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  KARAKTERISTIK KONDISI OSEANOGRAFI DAN DISTRIBU...   \n",
       "1  A STUDY OF METADISCOURSE MARKERS IN GRETA THUN...   \n",
       "2  Jaringan Sosial Pengusaha Kerajinan Limbah Kay...   \n",
       "3  Analisis strategi pengelolaan Pantai Syariah P...   \n",
       "4  MEMAKNAI GAYA HIDUP PENIKMAT KOPI KHAS INDONES...   \n",
       "5       Pertukaran Sosial Dalam Tradisi Sape Tok-tok   \n",
       "6  Public Awareness Masyarakat Madura Tentang Kon...   \n",
       "7  HUBUNGAN ANTARA PROKRASTINASI AKADEMIK DENGAN ...   \n",
       "8  Evaluasi Tingkat Kelelahan Kerja Perawat Ruang...   \n",
       "9  Pengaruh Biochar Sekam Padi dan Pupuk Kandang ...   \n",
       "\n",
       "                                           abstraksi  \n",
       "0  Laut Jawa (Wilayah Pengelolaan Perikanan/ WPP ...  \n",
       "1  Penelitian ini bertujuan untuk membahas jenis ...  \n",
       "2  Ana Febrianti, 160521100004 Program Studi Sosi...  \n",
       "3  Di Indonesia, potensi pengembangan Industri pa...  \n",
       "4  Siti Maghfuro 160521100023 Program Studi Sosio...  \n",
       "5  Abstrak – Farida Yulistiana Aji. \\n16052110000...  \n",
       "6  Penelitian ini dengan judul “Public Awareness ...  \n",
       "7  Penelitian ini bertujuan untuk mengetahui hubu...  \n",
       "8  Rumah sakit merupakan salah satu instansi di b...  \n",
       "9  Biochar merupakan padatan yang kaya kandungan ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b265cb",
   "metadata": {},
   "source": [
    "<h3>Pembersihan dokumen</h3>\n",
    "\n",
    "<p>Pembersihan dokumen diperlukan agar dalam proses TF/IDF tidak ada simbol-simbol yang ikut masuk ke dalam proses tersebut yang dapat mengakibatkan dokumen menjadi kurang otentik</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3dae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(headline):\n",
    "    le=WordNetLemmatizer()\n",
    "    word_tokens=word_tokenize(headline)\n",
    "    tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
    "    cleaned_text=\" \".join(tokens)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12deb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time taking\n",
    "df['abstrak_cleaned']=df['abstraksi'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861396e",
   "metadata": {},
   "source": [
    "<h3>Perbandingan data yang belum dan sudah dibersihkan</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b15dd74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>abstraksi</th>\n",
       "      <th>abstrak_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARAKTERISTIK KONDISI OSEANOGRAFI DAN DISTRIBU...</td>\n",
       "      <td>Laut Jawa (Wilayah Pengelolaan Perikanan/ WPP ...</td>\n",
       "      <td>Laut Jawa Wilayah Pengelolaan Perikanan/ perai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A STUDY OF METADISCOURSE MARKERS IN GRETA THUN...</td>\n",
       "      <td>Penelitian ini bertujuan untuk membahas jenis ...</td>\n",
       "      <td>Penelitian bertujuan membahas jenis tanda meta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jaringan Sosial Pengusaha Kerajinan Limbah Kay...</td>\n",
       "      <td>Ana Febrianti, 160521100004 Program Studi Sosi...</td>\n",
       "      <td>Febrianti 160521100004 Program Studi Sosiologi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analisis strategi pengelolaan Pantai Syariah P...</td>\n",
       "      <td>Di Indonesia, potensi pengembangan Industri pa...</td>\n",
       "      <td>Indonesia potensi pengembangan Industri pariwi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEMAKNAI GAYA HIDUP PENIKMAT KOPI KHAS INDONES...</td>\n",
       "      <td>Siti Maghfuro 160521100023 Program Studi Sosio...</td>\n",
       "      <td>Siti Maghfuro 160521100023 Program Studi Sosio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  KARAKTERISTIK KONDISI OSEANOGRAFI DAN DISTRIBU...   \n",
       "1  A STUDY OF METADISCOURSE MARKERS IN GRETA THUN...   \n",
       "2  Jaringan Sosial Pengusaha Kerajinan Limbah Kay...   \n",
       "3  Analisis strategi pengelolaan Pantai Syariah P...   \n",
       "4  MEMAKNAI GAYA HIDUP PENIKMAT KOPI KHAS INDONES...   \n",
       "\n",
       "                                           abstraksi  \\\n",
       "0  Laut Jawa (Wilayah Pengelolaan Perikanan/ WPP ...   \n",
       "1  Penelitian ini bertujuan untuk membahas jenis ...   \n",
       "2  Ana Febrianti, 160521100004 Program Studi Sosi...   \n",
       "3  Di Indonesia, potensi pengembangan Industri pa...   \n",
       "4  Siti Maghfuro 160521100023 Program Studi Sosio...   \n",
       "\n",
       "                                     abstrak_cleaned  \n",
       "0  Laut Jawa Wilayah Pengelolaan Perikanan/ perai...  \n",
       "1  Penelitian bertujuan membahas jenis tanda meta...  \n",
       "2  Febrianti 160521100004 Program Studi Sosiologi...  \n",
       "3  Indonesia potensi pengembangan Industri pariwi...  \n",
       "4  Siti Maghfuro 160521100023 Program Studi Sosio...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f426e",
   "metadata": {},
   "source": [
    "<p>Drop kolom abstraksi</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9097d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['abstraksi'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e8f7c",
   "metadata": {},
   "source": [
    "<p>Data frame kolom abstrak_cleaned</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98266d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Laut Jawa Wilayah Pengelolaan Perikanan/ perairan potensial habitat kelompok jenis ikan pelagis ekonomis Indonesia total estimasi potensi 981,680 ton/tahun Target penangkapan ikan Laut Jawa ikan pelagis Penangkapan ikan Laut Jawa malam bantuan cahaya lampu sasaran ikan berfototaksis positif Tujuan penelitian menganalisa distribusi kapal light fishing karakteristik parameter oseanografi kapal light fishing perairan Laut Jawa Penelitian data posisi kapal light fishing data harian 2016-2019 parameter oseanografi Salinitas diunduh CMEMS suhu Klorofil-a diunduh AQUA-Modis Level3 Hasil penelitian menunjukan distribusi dideteksi musim timur terendah musim barat Kondisi parameter oseanografi Laut Jawa suhu berkisar 27-34,5°C Klorofil-a berkisar 0,1-5 mg/m3 Salinitas berkisar 30-34,6 berkisar 0,44-0,77 meter Hasil ekstraksi data posisi kapal parameter oseanografi diindikasikan daerah light fishing kondisi oseanografi suhu 28-31°C klorofil-a berkisar 0,2-0,5 mg/m3 salinitas berkisar 32-33 muka laut berkisar 0,5-0,65 Kata Kunci Laut Jawa Light Fishing Parameter Oseanografi'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['abstrak_cleaned'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2df7d",
   "metadata": {},
   "source": [
    "## Term Frequency\n",
    "\n",
    "<p>Data di atas adalah data yang sudah diproses menggunakan TF-IDF untuk menentukan Term Frequency tiap topik. TF-IDF (Term Frequency - Inverse Document Frequency) adalah algoritma praktis yang menggunakan frekuensi kata untuk menentukan seberapa relevan kata-kata itu dengan dokumen tertentu. Ini adalah pendekatan yang relatif sederhana namun intuitif untuk pembobotan kata, memungkinkannya bertindak sebagai titik awal yang bagus untuk berbagai tugas.</p>\n",
    "<h3>Rumus TF-IDF</h3>\n",
    "\n",
    "$$\n",
    "\\operatorname{tf}(t, d)=\\frac{f_{t, d}}{\\sum_{t^{\\prime} \\in d} f_{t^{\\prime}, d}}\n",
    "$$\n",
    "\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5163d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect =TfidfVectorizer(stop_words=stop_words,max_features=1000) # to play with. min_df,max_df,max_features etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4886e1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WINDOWS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vect_text=vect.fit_transform(df['abstrak_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed3e0ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1000)\n",
      "         0         1         2         3         4         5         6    \\\n",
      "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "7   0.063018  0.066479  0.000000  0.000000  0.055319  0.000000  0.000000   \n",
      "8   0.245848  0.000000  0.049532  0.000000  0.215815  0.091960  0.000000   \n",
      "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "16  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "18  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "20  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "21  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "22  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "23  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "24  0.000000  0.000000  0.056851  0.000000  0.041284  0.000000  0.000000   \n",
      "25  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "26  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "27  0.063460  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "28  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "29  0.000000  0.052191  0.000000  0.000000  0.043430  0.000000  0.000000   \n",
      "30  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "31  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "32  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "33  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "34  0.113670  0.000000  0.000000  0.091605  0.000000  0.042519  0.000000   \n",
      "35  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "36  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "37  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "38  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "39  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "40  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "41  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "42  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "43  0.000000  0.000000  0.000000  0.128220  0.000000  0.000000  0.141177   \n",
      "44  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "45  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "46  0.042939  0.000000  0.000000  0.000000  0.037694  0.000000  0.000000   \n",
      "47  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "48  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "49  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "50  0.000000  0.094200  0.000000  0.000000  0.039193  0.000000  0.000000   \n",
      "51  0.000000  0.000000  0.000000  0.000000  0.031247  0.000000  0.000000   \n",
      "52  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "53  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "54  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "55  0.000000  0.034585  0.000000  0.000000  0.000000  0.036789  0.000000   \n",
      "56  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "57  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "58  0.000000  0.000000  0.000000  0.000000  0.043866  0.000000  0.000000   \n",
      "59  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "         7         8         9    ...       990       991       992       993  \\\n",
      "0   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "1   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.629329   \n",
      "4   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "5   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "6   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.472844   \n",
      "7   0.000000  0.000000  0.000000  ...  0.070716  0.000000  0.000000  0.000000   \n",
      "8   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "9   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "10  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "11  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "12  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "13  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.055938  0.000000   \n",
      "14  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "15  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "16  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "17  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "18  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "19  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "20  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "21  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "22  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "23  0.061522  0.058318  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "24  0.000000  0.000000  0.000000  ...  0.000000  0.056851  0.000000  0.000000   \n",
      "25  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "26  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "27  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "28  0.038932  0.036905  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "29  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "30  0.000000  0.062341  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "31  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "32  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "33  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.097858   \n",
      "34  0.039971  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "35  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "36  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "37  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "38  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "39  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "40  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "41  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "42  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "43  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "44  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "45  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "46  0.000000  0.000000  0.000000  ...  0.048185  0.000000  0.000000  0.000000   \n",
      "47  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "48  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.051627  0.000000   \n",
      "49  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "50  0.000000  0.000000  0.000000  ...  0.050102  0.000000  0.000000  0.000000   \n",
      "51  0.000000  0.000000  0.000000  ...  0.000000  0.043029  0.000000  0.000000   \n",
      "52  0.000000  0.031151  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "53  0.000000  0.040035  0.048396  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "54  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "55  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "56  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.144923   \n",
      "57  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "58  0.052716  0.000000  0.060406  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "59  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "         994       995       996       997       998       999  \n",
      "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3   0.221890  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.464901  \n",
      "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "16  0.000000  0.298984  0.000000  0.000000  0.000000  0.000000  \n",
      "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "18  0.000000  0.000000  0.000000  0.000000  0.362209  0.000000  \n",
      "19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "20  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "21  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "22  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "23  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "24  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "25  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "26  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "27  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "28  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "29  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "30  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "31  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "32  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "33  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "34  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "35  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "36  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "37  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "38  0.000000  0.000000  0.218091  0.000000  0.000000  0.000000  \n",
      "39  0.000000  0.000000  0.000000  0.124956  0.000000  0.000000  \n",
      "40  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "41  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "42  0.000000  0.000000  0.000000  0.000000  0.000000  0.338145  \n",
      "43  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "44  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "45  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "46  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "47  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "48  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "49  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "50  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "51  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "52  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "53  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "54  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "55  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "56  0.055355  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "57  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "58  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "59  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[60 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "print(vect_text.shape)\n",
    "#print(vect_text)\n",
    "type(vect_text)\n",
    "df=pd.DataFrame(vect_text.toarray())\n",
    "print(df)\n",
    "idf=vect.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eabcf312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penelitian zakat\n",
      "3.501435951739211\n",
      "3.164963715117998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WINDOWS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dd=dict(zip(vect.get_feature_names(), idf))\n",
    "l=sorted(dd, key=(dd).get)\n",
    "# print(l)\n",
    "print(l[0],l[-1])\n",
    "print(dd['jaringan'])\n",
    "print(dd['strategi'])  # police is most common and forecast is least common among the news headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123506c4",
   "metadata": {},
   "source": [
    "## Proses LSA\n",
    "\n",
    "<p>LSA  adalah metode yang memungkinkan kita mengekstrak topik dari dokumen dengan mengubah teksnya menjadi matriks topik-kata dan topik-dokumen. Prosedur untuk LSA relatif mudah: Ubah korpus teks menjadi matriks istilah dokumen. Menerapkan dekomposisi nilai singular terpotong.</p>\n",
    "\n",
    "$A_{m n}=U_{m m} x S_{m n} x V_{n n}^{T}$\n",
    "\n",
    "<p>Matriks U = baris merepresentasikan vektor pada topic dokumen</p>\n",
    "<p>Matriks V = Garis ini merepresentasikan vektor istilah yang dinyatakan pada topik</p>\n",
    "<p>Matriks S = Matriks diagonal yang memiliki elemen-elemen diagonal yang digunakan sebagai nilai singular A</p>\n",
    "\n",
    "<p>tiap baris pada matriks U merupakan representasi vektor yang terdapat pada dokumen yang sesuai, untuk melakukannya dapat menggunakan library Sklearn yang bernama TruncatedSVD untuk menimplementasikan LSA</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb3b78a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.06153173e-01 -4.04889332e-02  6.12160674e-02  4.58312267e-02\n",
      "   1.57819285e-02 -7.31249152e-02  1.07934847e-01  1.91987176e-01\n",
      "   3.21317895e-01 -3.86411102e-01]\n",
      " [ 7.34678089e-02 -9.83625445e-03 -7.48854394e-03 -3.21229303e-04\n",
      "  -8.35530608e-03  1.66583220e-02  7.45085438e-03  1.11982584e-02\n",
      "  -3.34062654e-02 -4.44699267e-02]\n",
      " [ 2.50698413e-01 -9.54330482e-02 -8.22691943e-02 -1.64814286e-01\n",
      "  -2.00113087e-01  1.35749630e-02  2.16535887e-02 -3.43899922e-02\n",
      "  -1.08412557e-01 -5.37433120e-02]\n",
      " [ 2.87867126e-01 -9.78614435e-02 -1.16258225e-01 -1.45714700e-01\n",
      "   2.43208959e-01 -1.08259114e-01  4.75555474e-02  7.24248880e-02\n",
      "   4.55415943e-01  4.29230224e-01]\n",
      " [ 1.95567729e-01 -7.17802134e-02 -4.80570276e-02 -8.77346362e-02\n",
      "  -9.35055215e-02 -1.87195481e-02  8.90404611e-03  5.98101282e-03\n",
      "  -3.41380599e-03 -2.29764579e-02]\n",
      " [ 2.28456957e-01 -1.21555458e-01 -1.02378651e-01 -2.46547199e-01\n",
      "  -2.57017297e-01 -6.75915419e-02 -3.52874892e-02 -2.18577397e-02\n",
      "  -1.10082802e-01 -7.23421606e-02]\n",
      " [ 3.40788593e-01 -1.40329411e-01 -2.04229186e-01 -2.47909845e-01\n",
      "   5.04845377e-01 -1.68487521e-03 -8.31733822e-02 -2.85153264e-02\n",
      "   2.13746215e-01  2.41210501e-01]\n",
      " [ 2.03147620e-01 -6.66492835e-02  1.30146414e-03  1.48297035e-01\n",
      "  -1.62760169e-01  6.81819946e-01  1.28367149e-01 -1.10679184e-02\n",
      "   1.51524535e-01  2.49695539e-02]\n",
      " [ 1.75010998e-01 -7.72467744e-02  3.03131574e-03  3.42669281e-01\n",
      "  -4.01892222e-02 -1.46941494e-02 -3.10424325e-01 -9.34218893e-02\n",
      "   1.20571517e-02 -7.21961251e-03]\n",
      " [ 9.98220704e-02 -1.07690898e-01  3.53908415e-01 -5.74652766e-02\n",
      "   2.08239093e-02 -4.73461411e-02 -5.30396037e-03  7.37787702e-02\n",
      "   1.59947706e-01 -2.71645581e-01]\n",
      " [ 1.43533422e-01 -1.79954360e-01  6.09873773e-01 -1.33556143e-01\n",
      "   3.75671659e-02 -2.92452377e-02 -2.26431126e-02  2.79855806e-02\n",
      "   8.43465761e-02 -1.64613161e-01]\n",
      " [ 3.59624813e-01  6.55882951e-01  9.59042042e-02 -4.77593255e-02\n",
      "   1.14271218e-02  2.33610072e-02 -5.16866132e-02 -1.78879695e-03\n",
      "  -1.04097822e-02  4.91397930e-02]\n",
      " [ 2.95419177e-01 -1.65781220e-01 -1.47732423e-01 -2.84672847e-01\n",
      "  -2.79006781e-01 -1.21193409e-01 -8.84392653e-02 -4.37573799e-03\n",
      "   4.39457281e-02  7.81920281e-02]\n",
      " [ 1.46687332e-01 -1.02067802e-02 -2.15063889e-02 -8.95491631e-03\n",
      "  -1.02181081e-02  2.38816810e-02  1.82665898e-02  3.82236058e-02\n",
      "   1.11030649e-02  5.84215693e-03]\n",
      " [ 3.34458318e-01 -9.46618598e-02 -1.18958006e-03  2.75679213e-01\n",
      "   1.69566040e-02 -1.39757873e-01  3.60934847e-01 -7.05058016e-02\n",
      "  -1.57888700e-01 -3.77163670e-03]\n",
      " [ 2.61946641e-01 -6.94243319e-02  3.54510090e-02  2.74465870e-01\n",
      "  -4.13047294e-02 -1.52920198e-01  4.38983309e-01 -3.73071723e-02\n",
      "  -1.78689423e-01  1.28258982e-01]\n",
      " [ 1.49724389e-01 -3.03774901e-02  7.44164316e-04  1.93511058e-01\n",
      "  -4.01111311e-02 -3.19537788e-02 -1.87958939e-01 -4.33697648e-02\n",
      "  -4.78484330e-02  2.22152314e-02]\n",
      " [ 1.57635999e-01 -6.03316153e-02 -7.28255273e-02 -1.03474318e-01\n",
      "   5.70137060e-02  7.76418491e-02  1.68324523e-02 -2.06110305e-02\n",
      "  -1.75731389e-01 -1.86665772e-01]\n",
      " [ 2.71494274e-01 -9.25609571e-02 -9.14919732e-02 -5.05943738e-02\n",
      "   1.91090033e-01  1.48975224e-01  5.89237221e-02 -2.78554468e-02\n",
      "  -2.25861133e-01 -2.31458521e-01]\n",
      " [ 2.40029647e-01  2.79422181e-01  1.08349080e-02 -1.11397405e-01\n",
      "  -5.67161271e-02 -3.24828118e-02 -6.02696239e-02 -2.86802782e-02\n",
      "   3.09607983e-02  3.00306368e-02]\n",
      " [ 1.36764802e-01 -2.06960490e-01  7.49028376e-01 -1.79410292e-01\n",
      "   7.41096615e-02  2.26105348e-02 -5.84820882e-02 -6.92067889e-02\n",
      "  -1.32126901e-01  1.97558900e-01]\n",
      " [ 1.56352418e-01 -4.36798416e-02 -7.50764287e-03  1.72737002e-01\n",
      "   2.35606915e-03 -5.73564799e-02 -1.53707032e-01  3.52690570e-01\n",
      "  -1.69433459e-01  5.68357991e-02]\n",
      " [ 1.23993244e-01 -2.20782037e-02  1.76579348e-02  6.30688279e-02\n",
      "   3.95076435e-02 -1.03957529e-01  1.25696669e-01  1.61423293e-01\n",
      "   3.18095786e-01 -2.90774211e-01]\n",
      " [ 1.04351187e-01 -1.74266297e-02  2.45522034e-02  1.98297269e-02\n",
      "  -9.66713283e-03 -5.38063073e-02  1.14783828e-01 -1.43952297e-03\n",
      "  -2.47288774e-02 -5.84912713e-02]\n",
      " [ 1.78493923e-01 -2.04709817e-02  1.24961723e-02  6.10416568e-02\n",
      "  -4.90064024e-02  4.09350583e-01  7.53362886e-02  8.50177715e-02\n",
      "  -1.16225268e-02  6.20841076e-02]\n",
      " [ 1.83966247e-01 -5.55608690e-02  3.30948303e-02  2.28586133e-01\n",
      "  -1.00166104e-02 -1.61036417e-01  4.61920441e-01 -4.95719898e-02\n",
      "  -1.65793254e-01  1.49845464e-01]\n",
      " [ 1.30809665e-01 -2.10440233e-01  7.68572645e-01 -1.85043227e-01\n",
      "   7.88004986e-02  2.43756209e-02 -6.13210675e-02 -7.08791672e-02\n",
      "  -1.34666599e-01  1.90283835e-01]\n",
      " [ 3.26424970e-01  5.80334183e-01  1.05628998e-01 -4.33104543e-02\n",
      "   1.93723047e-02 -2.20092648e-02 -5.41982222e-02 -4.71576233e-02\n",
      "  -1.30831165e-02 -6.57575466e-02]\n",
      " [ 1.05900741e-01 -2.54472325e-02  6.25006635e-03  3.87207766e-02\n",
      "   2.34455007e-02 -5.66073961e-02  8.75913189e-02  1.06651566e-01\n",
      "   1.99572740e-01 -4.65153183e-02]\n",
      " [ 2.76907527e-01 -1.00155515e-01  2.60624633e-02  4.65138129e-01\n",
      "  -6.76736063e-02 -9.36018015e-02 -2.00467914e-01 -1.41132005e-01\n",
      "  -6.39355156e-02  4.03235902e-02]\n",
      " [ 1.63888241e-01 -4.11569450e-02  5.06638971e-02  5.61131469e-02\n",
      "  -3.73320309e-03 -3.19166025e-02  1.20141248e-01  1.27872243e-01\n",
      "   2.29650172e-01 -2.91134160e-01]\n",
      " [ 2.79218597e-01 -1.37693030e-01 -1.67145556e-01 -1.08539243e-01\n",
      "   6.21490511e-01  9.10074625e-02 -6.63946042e-02 -4.86086474e-02\n",
      "  -1.67381585e-01 -1.09701786e-01]\n",
      " [ 2.86867001e-01  5.35398940e-01  8.99825400e-02 -6.18814595e-02\n",
      "   3.69485967e-02 -2.66082027e-02 -5.64348488e-02 -3.20927325e-02\n",
      "   1.39144820e-02 -5.63648391e-03]\n",
      " [ 1.75722431e-01 -2.35215949e-02 -2.45133870e-02  1.51747896e-02\n",
      "   5.22016724e-02 -9.34017493e-02  3.84518373e-02  8.44351447e-02\n",
      "   3.05338796e-01 -1.47793119e-03]\n",
      " [ 1.47966995e-01 -7.00713360e-02  6.57319149e-02  1.48081285e-01\n",
      "  -2.55929038e-02 -4.45479716e-02 -1.88796278e-01 -9.96267590e-03\n",
      "   1.49325018e-01 -1.90017489e-01]\n",
      " [ 2.06764672e-01  1.78495585e-02 -7.40935386e-03 -1.36478976e-02\n",
      "   4.88809986e-02 -7.03042018e-02  1.34284152e-01  1.46308895e-02\n",
      "   4.77743680e-02  1.01573954e-01]\n",
      " [ 3.03558629e-01 -1.55519485e-01 -1.94085023e-01 -1.44297669e-01\n",
      "   6.37098872e-01  1.85613940e-01 -8.32318412e-02 -7.15559784e-02\n",
      "  -2.39215030e-01 -2.43687989e-01]\n",
      " [ 1.38671676e-01 -5.13352879e-02 -1.15462244e-02  1.25203371e-01\n",
      "  -4.54449749e-02 -2.45672757e-02 -1.33701313e-01 -5.48575398e-02\n",
      "  -7.41713874e-02 -1.41850007e-02]\n",
      " [ 9.81110037e-02 -1.78678996e-02 -7.94956757e-03  5.86099306e-02\n",
      "   1.29242809e-02 -1.02156234e-02 -9.37225810e-02  7.05874693e-01\n",
      "  -2.27993996e-01  1.16901012e-01]\n",
      " [ 1.47286512e-01 -4.52791419e-02 -3.25432186e-02 -2.95422192e-02\n",
      "  -3.22416983e-02 -2.86105605e-02  2.02996806e-02  6.00297664e-03\n",
      "  -5.38038058e-02 -2.80726494e-02]\n",
      " [ 1.21956304e-01  9.52343995e-03  1.38286250e-02  5.20401101e-02\n",
      "   3.25019156e-02 -3.51008000e-02  8.52236477e-02  6.26651011e-02\n",
      "   4.93815030e-02 -1.97534194e-02]\n",
      " [ 2.17948673e-01 -4.47359112e-02 -2.99954635e-02 -2.83897101e-02\n",
      "  -9.33008754e-02  7.53358775e-02  9.90961539e-02  5.06819382e-05\n",
      "  -1.05121918e-01 -8.53576776e-02]\n",
      " [ 3.62935103e-01 -1.56603023e-01 -1.62681273e-01 -3.18569604e-01\n",
      "  -2.95070176e-01 -1.21513453e-01 -7.04386980e-02 -1.92681729e-02\n",
      "  -1.64221800e-02  2.41724950e-02]\n",
      " [ 1.25929792e-01 -2.07824697e-02  1.24839872e-02  7.15110595e-02\n",
      "   1.63625243e-02 -7.93839904e-02  1.34945509e-01  8.23362193e-02\n",
      "  -3.90712943e-02 -7.94921803e-02]\n",
      " [ 3.47580176e-01 -1.78302409e-01 -1.57345652e-01 -3.62310573e-01\n",
      "  -3.53131954e-01 -7.12421889e-02 -3.68547438e-02 -3.93784771e-02\n",
      "  -8.56283626e-02 -4.43645807e-02]\n",
      " [ 2.47677006e-01 -8.72499652e-03  1.69861123e-04  1.90083610e-01\n",
      "   1.21067667e-02 -1.32636209e-01  3.08550609e-01 -6.57423268e-02\n",
      "  -1.16557679e-01 -7.82203963e-02]\n",
      " [ 3.81197665e-01 -1.31214422e-01 -3.80897656e-03  4.55750093e-01\n",
      "  -9.00990534e-02 -4.90220217e-03 -3.42677391e-01 -1.31408299e-01\n",
      "   8.28763123e-02  4.84565683e-02]\n",
      " [ 3.66819043e-01 -1.54109267e-01 -1.30672513e-01 -3.19288713e-01\n",
      "  -3.36921833e-01 -3.83746722e-02 -2.92357312e-02 -2.77326924e-02\n",
      "  -7.66789329e-02 -4.79217319e-02]\n",
      " [ 1.99861754e-01 -4.95532883e-02 -3.03480894e-03  1.57396042e-01\n",
      "  -6.08269149e-02 -4.57725115e-02 -1.89232769e-01 -4.78604077e-02\n",
      "   4.78275305e-02 -1.12534439e-01]\n",
      " [ 1.52533436e-01  1.60415295e-01  1.78113809e-02 -1.96211076e-02\n",
      "  -4.07860664e-02  1.89554065e-01  6.49556794e-03  9.11827712e-02\n",
      "   9.87909509e-04  1.24630051e-01]\n",
      " [ 2.21742664e-01 -9.22918490e-02  6.98417761e-03  1.01710039e-01\n",
      "  -1.93851007e-01  6.21476683e-01  1.35798648e-01 -2.45308265e-02\n",
      "   1.62594022e-01  2.52183858e-02]\n",
      " [ 1.52417845e-01  5.81405915e-02  3.45363697e-02  4.67295426e-02\n",
      "  -5.37253536e-02  3.73329115e-01  4.15911702e-02  1.07538008e-01\n",
      "   7.34936427e-03  1.50220259e-01]\n",
      " [ 1.04355605e-01  7.07145455e-03 -8.86346865e-04  5.76077692e-02\n",
      "  -3.22520651e-03 -3.13314686e-02 -1.26416958e-01  7.26972530e-01\n",
      "  -1.80628788e-01  1.01089783e-01]\n",
      " [ 1.00067343e-01 -4.06988744e-02  5.59343760e-03  5.77285269e-02\n",
      "   8.47510976e-02 -7.80276649e-02  1.58318078e-01 -2.80045304e-02\n",
      "  -1.14425719e-01 -8.64502365e-03]\n",
      " [ 2.47918806e-01 -1.05869292e-01 -2.85413611e-02  3.38766609e-01\n",
      "   7.34085343e-03 -9.52647642e-02 -3.45285870e-01 -1.16573011e-01\n",
      "  -4.63130709e-02  1.67405383e-02]\n",
      " [ 8.20246446e-02 -4.21833813e-02  1.39049558e-01 -1.21055039e-04\n",
      "   1.03232198e-03 -1.34529436e-02  2.52722339e-02  1.11775346e-01\n",
      "   1.14447416e-01 -2.31500452e-01]\n",
      " [ 2.60216481e-01 -1.38524415e-01 -5.87148587e-02  3.97908213e-02\n",
      "   7.81353157e-02 -1.26508534e-01  9.64305362e-03 -1.62785231e-02\n",
      "   3.31037915e-01  3.31596211e-01]\n",
      " [ 3.81143389e-01  6.44455175e-01  1.05480271e-01 -6.52035343e-02\n",
      "   2.22753893e-02 -5.71520346e-02  5.56201839e-03 -6.88943619e-02\n",
      "  -2.95253841e-02 -3.78580143e-02]\n",
      " [ 9.77646744e-02 -4.12146581e-02  8.48118713e-02  3.21145366e-02\n",
      "  -1.74760702e-02 -4.34850336e-02  4.22535134e-02  6.84071233e-02\n",
      "   1.56162045e-01 -1.65195856e-01]\n",
      " [ 1.23290986e-01 -2.06492349e-02  6.82343767e-03  4.81347796e-02\n",
      "   4.10240152e-02 -1.01602500e-01  2.36258649e-01  8.64705146e-03\n",
      "   2.94539924e-02  1.79966160e-01]]\n",
      "(60, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=10, random_state=42)\n",
    "\n",
    "lsa_top=lsa_model.fit_transform(vect_text)\n",
    "print(lsa_top)\n",
    "print(lsa_top.shape)  # (no_of_doc*no_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1e34d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 :\n",
      "Topic  0  :  10.615317336988117\n",
      "Topic  1  :  -4.048893315556796\n",
      "Topic  2  :  6.121606740094335\n",
      "Topic  3  :  4.583122674813532\n",
      "Topic  4  :  1.5781928522040856\n",
      "Topic  5  :  -7.3124915175911145\n",
      "Topic  6  :  10.793484725991226\n",
      "Topic  7  :  19.198717598713902\n",
      "Topic  8  :  32.13178946757749\n",
      "Topic  9  :  -38.64111019991006\n"
     ]
    }
   ],
   "source": [
    "l=lsa_top[0]\n",
    "print(\"Document 0 :\")\n",
    "for i,topic in enumerate(l):\n",
    "  print(\"Topic \",i,\" : \",topic*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "507a4e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1000)\n",
      "[[ 3.68838453e-02  1.73717411e-02  6.32473900e-03 ...  6.18604097e-03\n",
      "   3.30547197e-02  8.74155242e-02]\n",
      " [ 2.13805687e-05 -9.65632006e-03 -2.43102682e-03 ... -2.76681134e-03\n",
      "  -1.63568072e-02 -6.33835619e-02]\n",
      " [ 7.48893280e-03  3.47604581e-03  4.42805804e-04 ... -2.04348593e-03\n",
      "  -1.67151577e-02 -6.23375515e-02]\n",
      " ...\n",
      " [-2.37082050e-02 -4.46456260e-03 -2.73535973e-06 ...  4.32974349e-04\n",
      "  -6.98248468e-03 -5.92131285e-03]\n",
      " [ 2.31196651e-02  1.82491007e-02  4.23603579e-05 ... -4.76079455e-03\n",
      "  -5.80949640e-02  9.76001544e-03]\n",
      " [-1.75759290e-02 -1.50289603e-03  2.40960725e-03 ... -2.55675632e-03\n",
      "  -6.19868442e-02  3.29305015e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape) # (no_of_topics*no_of_words)\n",
    "print(lsa_model.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3b06c",
   "metadata": {},
   "source": [
    "<h3>Hasil TruncatedSVD</h3>\n",
    "\n",
    "berikut adalah contoh 10 kata penting ditiap topik yang diproses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe7bba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "penelitian siswa kerja halal data masyarakat sosial wisata tradisi kualitas \n",
      "\n",
      "Topic 1: \n",
      "siswa pembelajaran guru miskonsepsi perangkat kemampuan pemecahan persentase belajar rendah \n",
      "\n",
      "Topic 2: \n",
      "pemangkasan pucuk tanaman bobot basah perlakuan kandang pupuk umur kering \n",
      "\n",
      "Topic 3: \n",
      "kerja variabel garam kualitas shift perusahaan karyawan tenaga kepuasan signifikan \n",
      "\n",
      "Topic 4: \n",
      "halal wisata literate literasi pariwisata chain sumenep value sertifikasi produk \n",
      "\n",
      "Topic 5: \n",
      "akademik prokrastinasi mahasiswa skala burnout coping anak regulasi psikologi korelasi \n",
      "\n",
      "Topic 6: \n",
      "perusahaan ratio bopo faktor harga pembelian signifikan produk bank berpengaruh \n",
      "\n",
      "Topic 7: \n",
      "risiko tsunami umroh haji tabung skenario pembiayaan manajemen foundation yulianto \n",
      "\n",
      "Topic 8: \n",
      "wisata pariwisata pantai ikan pulau klorofil syariah oseanografi perairan laut \n",
      "\n",
      "Topic 9: \n",
      "wisata pariwisata syariah pemangkasan pucuk bank anak risiko religi layanan \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vect.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36118212",
   "metadata": {},
   "source": [
    "## LDA (Latent Dirichlet Allocation)\n",
    "Latent Dirichlet Allocation (LDA) adalah teknik pemodelan topik yang populer untuk mengekstrak topik dari korpus tertentu. Istilah laten menyampaikan sesuatu yang sudah ada tetapi belum berkembang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6479f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_model=LatentDirichletAllocation(n_components=10,learning_method='online',random_state=42,max_iter=1) \n",
    "# n_components is the number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "162b0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_top=lda_model.fit_transform(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eb9bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 10)\n",
      "[[0.01500002 0.01499895 0.01499885 0.01499934 0.0149992  0.01499925\n",
      "  0.0149992  0.86500721 0.01499897 0.01499901]\n",
      " [0.01972556 0.01972723 0.01972538 0.01972536 0.01972535 0.82246959\n",
      "  0.01972524 0.01972541 0.01972565 0.01972524]\n",
      " [0.01671969 0.01671994 0.01671988 0.01672005 0.84951952 0.01672024\n",
      "  0.01671969 0.01671996 0.01672026 0.01672077]\n",
      " [0.01371976 0.01371997 0.01371978 0.01371974 0.01371978 0.0137199\n",
      "  0.01371985 0.01371981 0.87652157 0.01371983]\n",
      " [0.01625076 0.01625094 0.85373962 0.01625096 0.01625113 0.016251\n",
      "  0.01625091 0.01625096 0.016251   0.01625272]\n",
      " [0.01873823 0.01873851 0.01873854 0.01873828 0.01873855 0.01873864\n",
      "  0.01873842 0.01873867 0.01873889 0.83135327]\n",
      " [0.01819806 0.01819762 0.01819788 0.01819735 0.01819763 0.0181971\n",
      "  0.0181977  0.0181977  0.83622142 0.01819754]\n",
      " [0.01787393 0.01787349 0.01787406 0.83913471 0.01787413 0.01787404\n",
      "  0.01787436 0.01787383 0.0178735  0.01787394]\n",
      " [0.01771126 0.01771152 0.01771181 0.01771143 0.0177115  0.01771161\n",
      "  0.01771132 0.01771158 0.84059671 0.01771126]\n",
      " [0.01867547 0.01867512 0.01867548 0.01867552 0.01867552 0.01867534\n",
      "  0.8319208  0.01867595 0.01867523 0.01867556]\n",
      " [0.01505536 0.01505522 0.01505529 0.01505527 0.01505523 0.01505511\n",
      "  0.86450281 0.01505529 0.01505507 0.01505533]\n",
      " [0.01391209 0.01391217 0.01391207 0.01391215 0.0139122  0.01391199\n",
      "  0.01391213 0.01391216 0.01391471 0.87478833]\n",
      " [0.01537135 0.01537166 0.01537127 0.86165682 0.01537158 0.01537146\n",
      "  0.01537141 0.01537154 0.01537164 0.01537128]\n",
      " [0.01821659 0.01821658 0.83605014 0.01821662 0.01821688 0.01821692\n",
      "  0.01821646 0.01821628 0.01821681 0.01821672]\n",
      " [0.01758748 0.01758787 0.01758748 0.01758739 0.01758747 0.01758757\n",
      "  0.84171296 0.01758754 0.01758719 0.01758705]\n",
      " [0.01591865 0.01591839 0.01591852 0.01591852 0.01591831 0.85673374\n",
      "  0.01591852 0.01591848 0.01591845 0.01591839]\n",
      " [0.01576082 0.01576065 0.01576097 0.01576074 0.01576097 0.01576095\n",
      "  0.01576077 0.85815251 0.01576065 0.01576095]\n",
      " [0.01770984 0.01771029 0.01770979 0.0177098  0.01770988 0.01770989\n",
      "  0.01770975 0.01771007 0.84061093 0.01770976]\n",
      " [0.01774325 0.01774333 0.01774316 0.01774309 0.84030948 0.01774393\n",
      "  0.0177433  0.01774297 0.01774423 0.01774328]\n",
      " [0.01944227 0.82501655 0.01944267 0.01944239 0.01944238 0.01944319\n",
      "  0.01944257 0.01944259 0.01944268 0.0194427 ]\n",
      " [0.01608306 0.01608256 0.85525546 0.01608262 0.01608266 0.01608268\n",
      "  0.01608282 0.01608282 0.01608265 0.01608266]\n",
      " [0.01843288 0.01843304 0.83410368 0.01843275 0.01843278 0.01843297\n",
      "  0.01843275 0.01843315 0.01843298 0.01843303]\n",
      " [0.01518825 0.86330441 0.01518816 0.01518914 0.01518835 0.01518901\n",
      "  0.01518827 0.0151882  0.01518812 0.01518809]\n",
      " [0.84809327 0.01687901 0.01687841 0.01687831 0.01687844 0.01687853\n",
      "  0.01687875 0.01687833 0.01687856 0.0168784 ]\n",
      " [0.01685356 0.01685362 0.01685354 0.01685357 0.01685363 0.0168538\n",
      "  0.01685367 0.01685348 0.84831697 0.01685415]\n",
      " [0.01636726 0.01636711 0.01636767 0.01636749 0.0163671  0.01636751\n",
      "  0.01636738 0.8526943  0.0163671  0.0163671 ]\n",
      " [0.84470344 0.01725515 0.01725641 0.0172551  0.01725496 0.01725489\n",
      "  0.01725497 0.01725514 0.01725503 0.01725491]\n",
      " [0.02043251 0.02043331 0.02043301 0.02043279 0.02043412 0.02043297\n",
      "  0.02043322 0.02043263 0.81610234 0.0204331 ]\n",
      " [0.01678935 0.0167891  0.01678929 0.01678896 0.01678906 0.01678924\n",
      "  0.84889813 0.01678861 0.01678931 0.01678896]\n",
      " [0.01741361 0.01741351 0.84327875 0.01741343 0.01741332 0.01741371\n",
      "  0.01741343 0.01741335 0.0174134  0.01741348]\n",
      " [0.01501739 0.01501705 0.01501732 0.01501737 0.01501737 0.86484255\n",
      "  0.0150186  0.01501753 0.01501747 0.01501735]\n",
      " [0.01827418 0.01827408 0.01827467 0.01827454 0.01827418 0.01827434\n",
      "  0.01827457 0.01827437 0.8355298  0.01827525]\n",
      " [0.01589869 0.01589961 0.0158987  0.01589891 0.01589884 0.01589896\n",
      "  0.01589849 0.01589861 0.01589888 0.85691031]\n",
      " [0.01507026 0.01507038 0.01507033 0.86436517 0.01507061 0.01507056\n",
      "  0.01507062 0.01507065 0.01507103 0.01507038]\n",
      " [0.01701155 0.01701115 0.01701167 0.01701147 0.01701169 0.01701173\n",
      "  0.84689423 0.01701386 0.01701143 0.0170112 ]\n",
      " [0.01669303 0.01669298 0.01669362 0.01669285 0.01669285 0.8497632\n",
      "  0.01669293 0.01669288 0.01669289 0.01669277]\n",
      " [0.01852291 0.018523   0.01852371 0.01852282 0.01852412 0.01852322\n",
      "  0.01852328 0.01852286 0.83329075 0.01852333]\n",
      " [0.01914746 0.0191478  0.01914757 0.01914795 0.01914792 0.01914821\n",
      "  0.82766938 0.01914769 0.01914828 0.01914775]\n",
      " [0.01965153 0.82313806 0.01965144 0.01965151 0.01965097 0.01965136\n",
      "  0.01965147 0.0196512  0.01965124 0.01965121]\n",
      " [0.01648783 0.01648781 0.01648811 0.01648785 0.01648824 0.85160893\n",
      "  0.01648802 0.01648758 0.01648807 0.01648758]\n",
      " [0.01414955 0.01415262 0.01414953 0.01414974 0.01414943 0.01414959\n",
      "  0.01414975 0.01414968 0.01414963 0.87265048]\n",
      " [0.01639721 0.01639717 0.0163971  0.01639736 0.01639713 0.01639718\n",
      "  0.85242523 0.01639714 0.01639726 0.01639723]\n",
      " [0.01453884 0.01453902 0.01453876 0.01454056 0.01453905 0.86914831\n",
      "  0.01453883 0.01453893 0.01453897 0.01453873]\n",
      " [0.01511822 0.0151179  0.01511813 0.0151181  0.01511825 0.01511826\n",
      "  0.01511812 0.86393678 0.0151181  0.01511814]\n",
      " [0.01706639 0.0170671  0.01706644 0.01706634 0.01706654 0.01706652\n",
      "  0.01706627 0.01706639 0.84640159 0.01706643]\n",
      " [0.01586276 0.85723511 0.0158629  0.01586268 0.01586284 0.01586318\n",
      "  0.01586275 0.01586265 0.01586268 0.01586245]\n",
      " [0.01511592 0.01511608 0.01511826 0.01511577 0.01511602 0.86395352\n",
      "  0.01511617 0.01511618 0.01511606 0.01511601]\n",
      " [0.01481659 0.01481682 0.01481667 0.01481684 0.01481683 0.01481676\n",
      "  0.01481671 0.01481689 0.86664728 0.0148186 ]\n",
      " [0.01593543 0.01593535 0.8565799  0.01593533 0.01593547 0.0159355\n",
      "  0.01593554 0.01593551 0.01593627 0.01593571]\n",
      " [0.022812   0.02281247 0.02281245 0.02281283 0.79468672 0.02281271\n",
      "  0.02281253 0.02281283 0.02281252 0.02281294]\n",
      " [0.85656567 0.01593687 0.01593709 0.01593706 0.01593722 0.01593811\n",
      "  0.01593715 0.01593709 0.01593673 0.01593701]\n",
      " [0.01644607 0.85198419 0.01644608 0.01644605 0.01644618 0.01644689\n",
      "  0.01644603 0.01644616 0.01644616 0.01644619]\n",
      " [0.0220956  0.80114131 0.0220952  0.02209534 0.02209537 0.02209541\n",
      "  0.02209538 0.02209524 0.0220951  0.02209604]\n",
      " [0.01641141 0.01641155 0.01641135 0.85229629 0.01641154 0.01641145\n",
      "  0.01641149 0.01641134 0.01641146 0.01641214]\n",
      " [0.01634147 0.0163413  0.8529268  0.0163413  0.01634148 0.01634148\n",
      "  0.01634139 0.01634184 0.01634141 0.01634152]\n",
      " [0.01769692 0.01769683 0.01769704 0.84072809 0.01769694 0.01769647\n",
      "  0.0176971  0.01769691 0.01769679 0.01769691]\n",
      " [0.01501205 0.01501281 0.01501195 0.01501179 0.01501184 0.01501192\n",
      "  0.0150119  0.8648917  0.01501213 0.01501192]\n",
      " [0.01886753 0.83019404 0.01886743 0.01886707 0.01886737 0.01886709\n",
      "  0.01886738 0.0188672  0.01886776 0.01886713]\n",
      " [0.01593186 0.01593172 0.01593186 0.01593186 0.01593169 0.8566118\n",
      "  0.01593372 0.01593182 0.01593178 0.01593189]\n",
      " [0.02120889 0.02120907 0.80911727 0.02120891 0.02120932 0.02121049\n",
      "  0.02120865 0.02120926 0.02120887 0.02120927]]\n"
     ]
    }
   ],
   "source": [
    "print(lda_top.shape)  # (no_of_doc,no_of_topics)\n",
    "print(lda_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84e59ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "for i in lda_top[0]:\n",
    "  sum=sum+i\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64e8423a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: \n",
      "Topic  0 :  1.5000020109940448 %\n",
      "Topic  1 :  1.4998948522953661 %\n",
      "Topic  2 :  1.499884581428648 %\n",
      "Topic  3 :  1.4999342674692702 %\n",
      "Topic  4 :  1.4999198059980519 %\n",
      "Topic  5 :  1.499925398151928 %\n",
      "Topic  6 :  1.4999200935279642 %\n",
      "Topic  7 :  86.50072103441734 %\n",
      "Topic  8 :  1.499897235121079 %\n",
      "Topic  9 :  1.4999007205963226 %\n"
     ]
    }
   ],
   "source": [
    "# composition of doc 0 for eg\n",
    "print(\"Document 0: \")\n",
    "for i,topic in enumerate(lda_top[0]):\n",
    "  print(\"Topic \",i,\": \",topic*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd92c9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87031114 0.83571135 0.81044021 ... 0.92735631 0.75631235 0.84881569]\n",
      " [0.91109752 0.87067841 0.62901977 ... 0.82639955 0.85778536 1.05082305]\n",
      " [0.68888381 0.83642775 0.88243714 ... 0.93366613 0.77714325 0.80835197]\n",
      " ...\n",
      " [0.75684586 0.91820295 0.85334306 ... 0.79899825 0.67643385 0.81364844]\n",
      " [0.9953409  0.76222534 0.82673198 ... 0.88485638 0.79560402 0.8123469 ]\n",
      " [0.75327413 0.76478821 0.93785777 ... 0.87075443 0.69845767 0.72556051]]\n",
      "(10, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.components_)\n",
    "print(lda_model.components_.shape)  # (no_of_topics*no_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef85dd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "berkearifan sekunder tipe kecerdasan signifikan marketing pesisir aktor pekerja berprestasi \n",
      "\n",
      "Topic 1: \n",
      "pandangan ketapang risiko tipe laki rendah tsunami batik ziarah konsentrasi \n",
      "\n",
      "Topic 2: \n",
      "aspek sape kopi pola tourism penggunaan sentra mesin sampling alat \n",
      "\n",
      "Topic 3: \n",
      "stemming mahasiswa silika didalam menyimpulkan kesehatan karang makam fungsi tepung \n",
      "\n",
      "Topic 4: \n",
      "penelitian moment literate kabupaten kewirausahaan pemeriksaan gerbang menganalisis 00 program \n",
      "\n",
      "Topic 5: \n",
      "simultan tersendiri dianis rajungan rumah perairan fosfat kertasada sapi kebudayaan \n",
      "\n",
      "Topic 6: \n",
      "perlakuan masuk ton pokok manajemen media pembelian kholil peneliti sapi \n",
      "\n",
      "Topic 7: \n",
      "berkisar kepribadian layanan kebun sensor religi saham penilaian mengunakan jenuh \n",
      "\n",
      "Topic 8: \n",
      "singkong halal sumberdaya shift kecerahan time massa manten menikmati pertemuan \n",
      "\n",
      "Topic 9: \n",
      "pembelajaran subjek rendah aktual stasiun berkah jati pelagis 12 korelasi \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vect.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bcc3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
